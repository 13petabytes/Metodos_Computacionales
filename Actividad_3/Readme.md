# Reporte Actividad Integradora N.3

## Introducci√≥n

El proyecto actual, se presenta como un ejercicio de testeo de testeo de velocidad de compilado de un mismo ejercicio en diversos m√©todos de ejecuci√≥n, dichos m√©todos son los siguientes, ranqueados de mayor tiempo de ejecuci√≥n a menor: 


Secuencial, que indica que solo se ejecuta en un solo procesador o hilo. 

Paralelo, que se ejecuta en los n√∫meros de hilos o procesadores determinado por el programa, 11 en este caso.

CUDA, que es una plataforma de programaci√≥n paralela desarrollada por nvidia, que permite a los desarrolladores acelerar la ejecuci√≥n de programas muy demandantes, en este caso se emplearon 512 bloques, y 32 hilos , generando as√≠ una divisi√≥n en forma de matriz, a diferencia de la programaci√≥n en paralelo tradicional, limitada a 2 dimensiones.

En este caso, estos m√©todos ser√°n sometidos a la tarea de sumar los n√∫meros primos menores a 5 millones, como tal todos cumplen dicha tarea, dando como resultado 838596693108, pero de nuevo, lo importante no es esto, sino en cuanto tiempo lo hacen.

## Soluciones

### Desarrollo

Como tal todas las versiones realizadas siguiendo la misma estructura, main define el n√∫mero de hilos en los que ser√° dividida la tarea, de ser necesario, para posteriormente llamar a ‚ÄúsumarPrimos‚Äù, funci√≥n que con la ayuda de ‚ÄúesPrimo‚Äù, para detectar los n√∫meros requeridos, va sumando de uno en uno los n√∫meros. La complejidad seria representada de la siguiente forma:

<br>
<div align="center">
O(n‚àön)
</div>
</br>

Esto se debe a que por cada n√∫mero entre 1 y n se realiza una verificaci√≥n de primalidad que, en el peor de los casos, recorre hasta su ra√≠z cuadrada, generando as√≠ una complejidad compuesta que crece como el producto entre n y la ra√≠z de n. Todos los programas comparten la misma complejidad.

En los casos en los que se emple√≥ la divisi√≥n por hilos y la tecnolog√≠a CUDA, se divide el segmento de n√∫mero a checar y sumar, en el n√∫mero correspondiente de hilos, para posteriormente sumar las sumas echas por cada hilo. En el caso de CUDA, esto se profundiza, al tener 512 bloques, de cada uno 32 hilos, se podr√≠a decir que la divisi√≥n es similar a una matriz, donde cada columna es un arreglo de hilos, profundizando a√∫n m√°s la divisi√≥n del trabajo al elevarla a una tercera dimensi√≥n, y similar a los apuntes de Adam Smith, se eficienta m√°s el tiempo de trabajo a m√°s divisi√≥n de trabajo exista. Por lo que al comparar los 11 hilos que est√°n trabajando en el programa con programaci√≥n paralela con los 16,384 del desarrollado con CUDA podemos presuponer de antemano, cu√°l ser√° m√°s r√°pido.

### Tiempo de ejecuci√≥n y speed up

Procediendo a los resultados, estos son los tiempos de ejecuci√≥n de cada programa:

![image](https://github.com/user-attachments/assets/c837db2b-b62d-4adc-a601-05f1d0e41017)


	
Con esto podemos calcular tanto la eficiencia que las versiones que dividen presentan sobre el modelo de ejecuci√≥n secuencial, esto empleando el promedio del tiempo que tomo a cada una de las ejecuciones, permitiendo as√≠ el tener una vara de medir igual para cada m√©todo que busca mejorar el tiempo del algoritmo secuencial. Para esto se emplean las siguientes ecuaciones:


<br>
<div align="center">
	
Speed up = Tiempo de ejecuci√≥n secuencial / Tiempo de ejecuci√≥n a comparar

Eficiencia = Speed up / N√∫mero de procesadores totales empleados

</div>
</br>


Tabla con c√°lculos:

![image](https://github.com/user-attachments/assets/ddfdef4c-4551-49dd-81fe-2329e3c0a7f4)



### Conclusiones de los resultados

Al observar los resultados podemos confirmar los aseverado anteriormente, y es que el programa que emplea CUDA present√≥ una menor tiempo de ejecuci√≥n que el resto, a al par de un mayor speed up. Pero algo curioso se presenta en el c√°lculo de la eficiencia, y que el programa que solo divide en 11 hilos presenta una tres d√≠gitos mayor que la del desarrollado con cuidado. Pudiendo concluir as√≠, que el tiempo que ahorra cada hilo agregado a la ejecuci√≥n va bajando su valor conforma m√°s hilos existan ejecutando dicha acci√≥n actualmente, o en otras palabras, el valor de divisi√≥n de trabajo que cada hilo presenta a un programa de n hilos es menor que si el programa tuviera n -1 hilos. 

Para mejor entendimiento de esto, tenemos esta gr√°fica, donde las abscisas representan el n√∫mero de hilos y las abscisas la eficiencia, el punto representa el n√∫mero de hilos y la eficiencia del programa con 11 hilos (11,6.5/11):

![image](https://github.com/user-attachments/assets/224ea768-a0b1-4826-98c2-25f66e4d29f5)


La ecuaci√≥n empleada para esto es la siguiente:

<br>
<div align="center">
	
E(P) = S(P) / P

</div>
</br>
	
Donde E(P) representa el cu√°nto valdr√°  la eficiencia, S(P) el Speed up en base al n√∫mero de hilos y P el n√∫mero de hilos. Como se puede concluir a simple vista, el valor que nos da un speed up tambi√©n nos la da una funci√≥n. Esta se define de la siguiente forma:

<br>
<div align="center">
S(P)= 5.0942 + 0.5862 * ln(P)
</div>
</br>

Gr√°fica de la f√≥rmula. El eje x representa el n√∫mero de hilos y el eje y el incremento en la eficiencia:

![image](https://github.com/user-attachments/assets/b91ae663-9abd-4fcb-af7c-bd2ffb8df7e1)


Al observar el comportamiento del speed up en funci√≥n del n√∫mero de hilos 
ùëÉ
P, notamos que la aceleraci√≥n crece r√°pido al inicio, pero conforme aumentan los hilos, la mejora se vuelve cada vez m√°s lenta. Por eso se eligi√≥ una funci√≥n logar√≠tmica para ajustarlo, que tiene la forma:

<br> 
<div align="center">
	S(P) = 5.0942 + 0.5862 * ln(P)
</div> 
</br>

Los n√∫meros 5.0942 y 0.5862 son constantes calculadas a partir de los dos puntos conocidos: un speed up de 6.5 con 11 hilos y uno de 10.7832 con 16384 hilos. Para obtener estos valores se resolvi√≥ un sistema de ecuaciones usando el logaritmo natural de 
ùëÉ
P. Esta ecuaci√≥n no pretende ser una f√≥rmula exacta de eficiencia, sino una aproximaci√≥n que refleja el comportamiento observado en los datos.

De esta forma, se puede demostrar que el speed up crece pero con un rendimiento decreciente conforme se agregan m√°s hilos, concepto que tambi√©n es consistente con la Ley de Amdahl.

Para entender c√≥mo se obtuvieron los coeficientes, se resolvi√≥ el siguiente sistema con los puntos conocidos:

<br> 
<div align="center"> 
	6.5 = a + b * ln(11)
	
</div> 
<div align="center"> 
10.7832 = a + b * ln(16384)
</div>
</br>

De donde se obtuvo:

<br> <div align="center">

a = 5.0942

<div align="center"> 
b = 0.5862
</div>
</div> </br>
y as√≠ la funci√≥n ajustada queda:

<br> <div align="center"> S(P) = 5.0942 + 0.5862 * ln(P)</div> </br>
Por otro lado, la Ley de Amdahl permite calcular la mejora m√°xima que se puede obtener al paralelizar una fracci√≥n 
ùëù
p de un sistema, seg√∫n la ecuaci√≥n:

<br> <div align="center">  S = 1  /  (1 - p + p / s) </div> </br>
Donde 
ùëù
p es la fracci√≥n paralelizable del sistema y 
ùë†
s el factor de aceleraci√≥n de dicha parte. Eugene Myron Amdahl indica que, al tender 
ùëù
p a infinito (en este caso, 
ùëù
‚âà
0.907
p‚âà0.907), el valor resultante del speed up es cercano a 10.75, lo cual concuerda con el valor experimental obtenido para 16384 hilos. Esto confirma que el modelo logar√≠tmico y la Ley de Amdahl se complementan en la explicaci√≥n del comportamiento del speed up.

En conclusi√≥n, un mayor n√∫mero de hilos reduce el tiempo de ejecuci√≥n, pero el beneficio que aporta cada hilo disminuye conforme aumenta el total de hilos ejecut√°ndose.

## Conclusiones personales del proyecto y la clase

Si bien no voy a continuar mi vida universitaria en la carrera de ITC, he podido disfrutar de la clase, y en particular de este proyecto,  debido a su relaci√≥n con teoremas matem√°ticos, en los que me hubiera gustado profundizar m√°s. Pude darme cuenta que genuinamente me faltaban matem√°ticas para darle cuerpo a la teor√≠a con la que trabajaba. Me llevo buenas experiencias y necesarias reflexiones sobre mi deseo vocacional. Muchas gracias por el semestre.


# Referencias:

Amdahl, Gene M. (1967). "Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities" (PDF). AFIPS Conference Proceedings (30): 483‚Äì485. doi:10.1145/1465482.1465560. S2CID 195607370.


